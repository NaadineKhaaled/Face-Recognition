{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaadineKhaaled/Face-Recognition/blob/main/FaceRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGO4bdP1yYu4"
      },
      "source": [
        "The dataset has 10 images per 40 subjects. Every image is a grayscale\n",
        "image of size 92x112."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdAjbHWlyidk"
      },
      "source": [
        "Generate the Data Matrix and the Label vector \n",
        "a. Convert every image into a vector of 10304 values corresponding to the\n",
        "image size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lheqz850yphx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "from math import sqrt\n",
        "import cv2\n",
        "from sklearn import datasets\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sn\n",
        "import sys\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from scipy import linalg\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeHzL2yipGXu"
      },
      "source": [
        "1. Downloading the Dataset\n",
        "\n",
        "2. Generate the Data Matrix and the Label vector \n",
        "\n",
        "3. Split the Dataset into Training and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QxWTYBdz-SU"
      },
      "source": [
        "BASE = '/content/drive/MyDrive/Colab Notebooks/FaceRecognition/att-database-of-faces'\n",
        "Base2 = '/content/drive/MyDrive/Colab Notebooks/FaceRecognition/Flowerpgm'\n",
        "matrix = []\n",
        "new_matrix = []#Q7 iii\n",
        "matrix_Mix = []#Q7\n",
        "training=[]\n",
        "testing=[]\n",
        "trainingLabel=[]\n",
        "testingLabel=[]\n",
        "trainingLabel_Mix= [] #Q7\n",
        "testingLabel_Mix = [] #Q7\n",
        "new_TrainingLabel = []#Q7 iii\n",
        "new_TestingLabel = []#Q7 iii\n",
        "count=0\n",
        "\n",
        "for i in range(1,41):\n",
        "  for j in range(1,11):\n",
        "    img = cv2.imread(BASE + '/s'+ str(i)+ '/'+ str(j)+ '.pgm' , 0) # '0' for reading grayscale images \n",
        "    x,y= img.shape\n",
        "    vectorFlattened= img.reshape(x * y, 1).flatten()  \n",
        "    if(j%2==1):\n",
        "      training.append(vectorFlattened)\n",
        "      trainingLabel.append(i)\n",
        "      trainingLabel_Mix.append(1)\n",
        "      new_TrainingLabel.append(1)\n",
        "    else:\n",
        "      testing.append(vectorFlattened)\n",
        "      testingLabel.append(i)\n",
        "      testingLabel_Mix.append(1)\n",
        "      new_TestingLabel.append(1)  \n",
        "    \n",
        "    matrix.append(vectorFlattened)\n",
        "    matrix_Mix.append(vectorFlattened)\n",
        "    new_matrix.append(vectorFlattened)\n",
        "\n",
        "DataMatrix= np.asarray(matrix)\n",
        "training_Matrix= np.asarray(training)\n",
        "testing_Matrix=np.asarray(testing)\n",
        "\n",
        "\n",
        "# plt.imshow(img, cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.title('A random grumpy person')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgQjq4ki_pHl",
        "outputId": "51238e60-7cac-4bb5-9135-4f1d047635d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRrEEnnmpp7E"
      },
      "source": [
        "4) Classification using PCA\n",
        "\n",
        "  a.Use the pseudo code below for computing the projection matrix U.\n",
        "  \n",
        "Define the alpha = {0.8,0.85,0.9,0.95}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij6zCVhNqNod"
      },
      "source": [
        "\n",
        "mean=np.mean(DataMatrix,axis=0)\n",
        "centered=DataMatrix-mean\n",
        "covarience=np.cov(training_Matrix.T)\n",
        "\n",
        "EigenValues_PCA,EigenVectors_PCA= np.linalg.eigh(covarience)\n",
        "print('Covariance Mat Shape:'+ str(covarience.shape))\n",
        "indices = np.argsort(EigenValues_PCA)[::-1]\n",
        "EigenValues_PCA = EigenValues_PCA[indices]\n",
        "EigenVectors_PCA = EigenVectors_PCA[:,indices]\n",
        "print('Eigen'+str(EigenValues_PCA))\n",
        "Sum=sum(EigenValues_PCA)\n",
        "\n",
        "List1 = []\n",
        "List2 = []\n",
        "List3 = []\n",
        "List4 = []\n",
        "prev=0\n",
        "for k in range(len(EigenValues_PCA)):\n",
        "  prev+=EigenValues_PCA[k]\n",
        "  Alpha=(prev)/Sum\n",
        "  if(Alpha<=0.8):   \n",
        "    List1.append(EigenVectors_PCA[:,k])\n",
        "  if(Alpha<=0.85):\n",
        "    List2.append(EigenVectors_PCA[:,k])\n",
        "  if(Alpha<=0.90):\n",
        "    List3.append(EigenVectors_PCA[:,k])\n",
        "  if(Alpha<=0.95):\n",
        "    List4.append(EigenVectors_PCA[:,k])  \n",
        "  else:\n",
        "    break  \n",
        "\n",
        "projection_matrix1=np.transpose(List1)\n",
        "projection_matrix2=np.transpose(List2)\n",
        "projection_matrix3=np.transpose(List3)\n",
        "projection_matrix4=np.transpose(List4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_my8SkQKqTRI"
      },
      "source": [
        "b. Project the training set, and test sets separately using the same\n",
        "projection matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87kGilYJwzwC"
      },
      "source": [
        "projectedtesting1=np.dot(testing_Matrix,projection_matrix1)\n",
        "projectedtraining1=np.dot(training_Matrix,projection_matrix1)\n",
        "\n",
        "projectedtesting2=np.dot(testing_Matrix,projection_matrix2)\n",
        "projectedtraining2=np.dot(training_Matrix,projection_matrix2)\n",
        "\n",
        "projectedtesting3=np.dot(testing_Matrix,projection_matrix3)\n",
        "projectedtraining3=np.dot(training_Matrix,projection_matrix3)\n",
        "\n",
        "projectedtesting4=np.dot(testing_Matrix,projection_matrix4)\n",
        "projectedtraining4=np.dot(training_Matrix,projection_matrix4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrOfb4OixEFq"
      },
      "source": [
        "c. Use a simple classifier (first Nearest Neighbor to determine the class labels).\n",
        "\n",
        "d. Report Accuracy for every value of alpha separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phj5nf1UxGjP"
      },
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining1,trainingLabel)\n",
        "\n",
        "Testing_Label1 = classifier.predict(projectedtesting1)\n",
        "#print(Testing_Label1)\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining2,trainingLabel)\n",
        "\n",
        "Testing_Label2 = classifier.predict(projectedtesting2)\n",
        "#print(Testing_Label2)\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining3,trainingLabel)\n",
        "\n",
        "Testing_Label3 = classifier.predict(projectedtesting3)\n",
        "#print(Testing_Label3)\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining4,trainingLabel)\n",
        "\n",
        "Testing_Label4 = classifier.predict(projectedtesting4)\n",
        "#print(Testing_Label4)\n",
        "\n",
        "Acc_score1 = accuracy_score(testingLabel, Testing_Label1)\n",
        "print(Acc_score1)\n",
        "Acc_score2 = accuracy_score(testingLabel, Testing_Label2)\n",
        "print(Acc_score2)\n",
        "Acc_score3 = accuracy_score(testingLabel, Testing_Label3)\n",
        "print(Acc_score3)\n",
        "Acc_score4 = accuracy_score(testingLabel, Testing_Label4)\n",
        "print(Acc_score4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCQfJVh_xyYO"
      },
      "source": [
        "5. Classification Using LDA \n",
        "\n",
        "a. Use the pseudo code below for LDA. We will modify few lines in\n",
        "pseudocode to handle multiclass LDA.\n",
        "\n",
        "i. Calculate the mean vector for every class Mu1, Mu2, ..., Mu40.\n",
        "\n",
        "ii. Replace B matrix by Sb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcSBAGEIx2_4"
      },
      "source": [
        "\n",
        "MeanClass_Training= []\n",
        "\n",
        "for i in range(0,200,5):\n",
        "  newMatrix_Training=training_Matrix[i: i+5,:]\n",
        "  M=np.mean(newMatrix_Training,axis=0)\n",
        "  MeanClass_Training.append(M)\n",
        " \n",
        "MeanClass_TrainingArray=np.asarray(MeanClass_Training)\n",
        "\n",
        "B_MatrixTraining= np.zeros((10304, 10304))\n",
        "\n",
        "print('Mean shape= '+str(mean.shape))\n",
        "\n",
        "for j in range(40):\n",
        "  MeanK=MeanClass_TrainingArray[j]-mean\n",
        "  MeanKT=MeanK.T\n",
        "  MeanProductK=5*(np.outer(MeanK,MeanKT))\n",
        "  B_MatrixTraining= B_MatrixTraining + MeanProductK\n",
        "\n",
        "# print('B_Matrix Training ='+str(B_MatrixTraining))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gonDN80Vyfsv"
      },
      "source": [
        "iii. S matrix remains the same, but it sums S1, S2, S3, ...S40.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3cljk9hyg3Q"
      },
      "source": [
        "S_Matrix= np.zeros((10304,10304))\n",
        "\n",
        "for i in range(40):\n",
        "  centeredLda=np.subtract(training_Matrix[i],MeanClass_TrainingArray[i])\n",
        "  centered_Transposed=centeredLda.T\n",
        "  centered_lda_product=np.outer(centered_Transposed,centeredLda)\n",
        "  S_Matrix=S_Matrix+centered_lda_product\n",
        "\n",
        "\n",
        "# print('S_Matrix: '+ str(S_Matrix))\n",
        "A = linalg.pinv(S_Matrix).dot(B_MatrixTraining)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJeawOfnzN4N"
      },
      "source": [
        "iv. Use 39 dominant eigenvectors instead of just one. You will\n",
        "\n",
        "have a projection matrix U39x10304.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPebBe_KzP0o"
      },
      "source": [
        "\n",
        "EigenValues_LDA , EigenVctors_LDA = np.linalg.eigh(A)\n",
        "indices = np.argsort(EigenValues_LDA)[::-1]\n",
        "EigenValues_LDA = EigenValues_LDA[indices]\n",
        "EigenVctors_LDA = EigenVctors_LDA[:,indices]\n",
        "\n",
        "DominantVectors = []\n",
        "\n",
        "for i in range(39):\n",
        "\n",
        "  DominantVectors.append(EigenVctors_LDA[:,i])\n",
        "\n",
        "print('Size of Dom = '+ str(len(DominantVectors)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcrTIHHjzdKu"
      },
      "source": [
        "b. Project the training set, and test sets separately using the same\n",
        "projection matrix U. You will have 39 dimensions in the new space.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2o74rcwzeVy"
      },
      "source": [
        "\n",
        "LDA_ProjectionMatrix= np.transpose(DominantVectors)\n",
        "LDA_Projected_Training= np.dot(training_Matrix,LDA_ProjectionMatrix)\n",
        "LDA_Projected_Testing= np.dot(testing_Matrix,LDA_ProjectionMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsPY2O__zotK"
      },
      "source": [
        "c. Use a simple classifier (first Nearest Neighbor to determine the class labels).\n",
        "\n",
        "d. Report Accuracy for the Multiclass LDA on the face recognition\n",
        "dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96du_pWzyMx"
      },
      "source": [
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "classifier.fit(LDA_Projected_Training,trainingLabel)\n",
        "\n",
        "Testing_Label_LDA = classifier.predict(LDA_Projected_Testing) \n",
        "# print(Testing_Label_LDA)\n",
        "\n",
        "Acc_score_LDA = accuracy_score(testingLabel, Testing_Label_LDA)\n",
        "print('Accuracy Score for LDA using 39 EigenVectors: ' + str(Acc_score_LDA))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVpoKtUI0PM7"
      },
      "source": [
        "6. Classifier Tuning \n",
        "\n",
        "a. Set the number of neighbors in the K-NN classifier to 1,3,5,7.\n",
        "(Using PCA)\n",
        "\n",
        "c. Plot (or tabulate) the performance measure (accuracy) against the K\n",
        "value. This is to be done for PCA and LDA as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqFM4dx0V7X"
      },
      "source": [
        "\n",
        "kList = [1, 3, 5, 7]\n",
        "#PCA\n",
        "#Alpha = 0.80 K = 1\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining1,trainingLabel)\n",
        "\n",
        "Label1_PCA = classifier.predict(projectedtesting1)\n",
        "#print('PCA k=1 '+ str(Label1_PCA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=3,weights='distance')\n",
        "classifier.fit(projectedtraining1,trainingLabel)\n",
        "\n",
        "Label2_PCA= classifier.predict(projectedtesting1)\n",
        "#print('PCA k=3 '+ str(Label2_PCA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
        "classifier.fit(projectedtraining1,trainingLabel)\n",
        "\n",
        "Label3_PCA = classifier.predict(projectedtesting1)\n",
        "#print('PCA k=5 '+ str(Label3_PCA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
        "classifier.fit(projectedtraining1,trainingLabel)\n",
        "\n",
        "Label4_PCA = classifier.predict(projectedtesting1)\n",
        "#print('PCA k=7 '+ str(Label4_PCA))\n",
        "\n",
        "Acc_score_PCA_k1 = accuracy_score(testingLabel, Label1_PCA)\n",
        "print('PCA k=1 Acc Score:'+str(Acc_score_PCA_k1))\n",
        "\n",
        "Acc_score_PCA_k3 = accuracy_score(testingLabel, Label2_PCA)\n",
        "print('PCA k=3 Acc Score:'+str(Acc_score_PCA_k3))\n",
        "\n",
        "Acc_score_PCA_k5 = accuracy_score(testingLabel, Label3_PCA)\n",
        "print('PCA k=5 Acc Score:'+str(Acc_score_PCA_k5))\n",
        "\n",
        "Acc_score_PCA_k7 = accuracy_score(testingLabel, Label4_PCA)\n",
        "print('PCA k=7 Acc Score:'+str(Acc_score_PCA_k7))\n",
        "\n",
        "PCA_Accuracies = [Acc_score_PCA_k1, Acc_score_PCA_k3, Acc_score_PCA_k5, Acc_score_PCA_k7]\n",
        " \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(kList, PCA_Accuracies)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('PCA Accuracy vs k value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgzxJyIX0zKw"
      },
      "source": [
        "\n",
        "a. Set the number of neighbors in the K-NN classifier to 1,3,5,7.\n",
        "(Using LDA)\n",
        "\n",
        "c. Plot (or tabulate) the performance measure (accuracy) against the K\n",
        "value. This is to be done for PCA and LDA as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1zj2rs602IN"
      },
      "source": [
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training,trainingLabel)\n",
        "\n",
        "Label1_LDA = classifier.predict(LDA_Projected_Testing) \n",
        "#print('LDA k=1 '+ str(Label1_LDA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=3,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training,trainingLabel)\n",
        "\n",
        "Label2_LDA = classifier.predict(LDA_Projected_Testing) \n",
        "#print('LDA k=3 '+ str(Label2_LDA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training,trainingLabel)\n",
        "\n",
        "Label3_LDA = classifier.predict(LDA_Projected_Testing) \n",
        "#print('LDA k=5 '+ str(Label3_LDA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training,trainingLabel)\n",
        "\n",
        "Label4_LDA = classifier.predict(LDA_Projected_Testing) \n",
        "#print('LDA k=7 '+ str(Label4_LDA))\n",
        "\n",
        "Acc_score_LDA_k1 = accuracy_score(testingLabel, Label1_LDA)\n",
        "print('LDA k=1 Acc Score:'+str(Acc_score_LDA_k1))\n",
        "\n",
        "Acc_score_LDA_k3 = accuracy_score(testingLabel, Label2_LDA)\n",
        "print('LDA k=3 Acc Score:'+str(Acc_score_LDA_k3))\n",
        "\n",
        "Acc_score_LDA_k5 = accuracy_score(testingLabel, Label3_LDA)\n",
        "print('LDA k=5 Acc Score:'+str(Acc_score_LDA_k5))\n",
        "\n",
        "Acc_score_LDA_k7 = accuracy_score(testingLabel, Label4_LDA)\n",
        "print('LDA k=7 Acc Score:'+str(Acc_score_LDA_k7))\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "LDA_Accuracies = [Acc_score_LDA_k1, Acc_score_LDA_k3, Acc_score_LDA_k5, Acc_score_LDA_k7]\n",
        "plt.plot(kList, LDA_Accuracies)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('LDA Accuracy vs k value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD_Xyfb71KI9"
      },
      "source": [
        "7. Compare vs Non-Face Images \n",
        "\n",
        "a. Download non-face images and make them of the same size 92x112.\n",
        "and try to solve the classification problem faces vs. Non-faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1KO5mYD1P2L"
      },
      "source": [
        "\n",
        "training_Mix = training\n",
        "testing_Mix = testing\n",
        "#matrix_Mix=new_matrix#matrix#either 400 and 400 or 200 and 200 total matrix\n",
        "\n",
        "# print('Lenghth of training Face: '+ str(len(training_Mix)))\n",
        "# print('Lenghth of matrix Face: '+ str(len(matrix_Mix)))\n",
        "\n",
        "for k in range(400):\n",
        "\n",
        "    if(k<10):\n",
        "      img2 = cv2.imread(Base2 + '/AnyConv.com__flower_000'+ str(k)+ '.pgm' , 0)\n",
        "      img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "    elif(k<100):\n",
        "      img2 = cv2.imread(Base2 + '/AnyConv.com__flower_00'+ str(k)+ '.pgm' , 0)\n",
        "      img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "    else:\n",
        "      img2 = cv2.imread(Base2 + '/AnyConv.com__flower_0'+ str(k)+ '.pgm' , 0)\n",
        "      img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    x2,y2= img2_resize.shape\n",
        "    vectorFlattened2= img2_resize.reshape(x2 * y2, 1).flatten()  \n",
        "    if(k%2==1):\n",
        "      training_Mix.append(vectorFlattened2)\n",
        "      trainingLabel_Mix.append(2)\n",
        "    else:\n",
        "      testing_Mix.append(vectorFlattened2)\n",
        "      testingLabel_Mix.append(2)  \n",
        "   \n",
        "    matrix_Mix.append(vectorFlattened2)\n",
        "\n",
        "# print('len of Training = '+str(len(training_Mix)))\n",
        "DataMatrix_Mix=np.asarray(matrix_Mix)\n",
        "training_Matrix_Mix= np.asarray(training_Mix)\n",
        "testing_Matrix_Mix=np.asarray(testing_Mix)\n",
        "# print(trainingLabel_Mix)\n",
        "# print(img2_resize.shape)\n",
        "# print(DataMatrix_Mix.shape)\n",
        "\n",
        "# plt.imshow(img2, cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.title('Flower img')\n",
        "# plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdMnbHaG1jGO"
      },
      "source": [
        "i. Show failure and success cases.\n",
        "\n",
        "ii. How many dominant eigenvectors will you use for the LDA\n",
        "solution?  (We Used Eigen Vectors using default alpha = 0.95)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6N4J6ZB1nDC"
      },
      "source": [
        "Mean_Mix=np.mean(DataMatrix_Mix,axis=0)\n",
        "MeanClass_TrainingMix= []\n",
        "\n",
        "# Mean of first class (Faces)\n",
        "FaceMatrix_Training=training_Matrix_Mix[0:200,:]\n",
        "M1=np.mean(FaceMatrix_Training,axis=0)\n",
        "MeanClass_TrainingMix.append(M1)\n",
        "\n",
        "#Mean of second class (Non-Faces)\n",
        "NonFaceMatrix_Training=training_Matrix_Mix[200:400,:]\n",
        "M2=np.mean(NonFaceMatrix_Training,axis=0)\n",
        "MeanClass_TrainingMix.append(M2)\n",
        " \n",
        "MeanClass_TrainingArrayMix=np.asarray(MeanClass_TrainingMix)\n",
        "#print('meanclassmix'+str(MeanClass_TrainingArrayMix.shape))\n",
        "\n",
        "B_MatrixTraining_Mix= np.zeros((10304, 10304))\n",
        "\n",
        "#print('Mean Class Training Array shape= '+str(MeanClass_TrainingArrayMix.shape))\n",
        "\n",
        "for j in range(2):\n",
        "  MeanK=MeanClass_TrainingArrayMix[j]-Mean_Mix\n",
        "  MeanKT=MeanK.T\n",
        "  MeanProductK=2*(np.outer(MeanK,MeanKT))\n",
        "  B_MatrixTraining_Mix= B_MatrixTraining_Mix + MeanProductK\n",
        "\n",
        "#print('B_Matrix Training ='+str(B_MatrixTraining_Mix.shape))\n",
        "\n",
        "S_Matrix_Mix= np.zeros((10304,10304))\n",
        "\n",
        "for i in range(2):\n",
        "  centeredLda=np.subtract(training_Matrix_Mix[i],MeanClass_TrainingArrayMix[i])\n",
        "  centered_Transposed=centeredLda.T\n",
        "  centered_lda_product=np.outer(centered_Transposed,centeredLda)\n",
        "  S_Matrix_Mix=S_Matrix_Mix+centered_lda_product\n",
        "\n",
        "\n",
        "#print('S_Matrix: '+ str(S_Matrix_Mix.shape))\n",
        "\n",
        "A = linalg.pinv(S_Matrix_Mix).dot(B_MatrixTraining_Mix)\n",
        "\n",
        "\n",
        "EigenValuesMix_LDA , EigenVectorsMix_LDA = np.linalg.eigh(A)\n",
        "indices = np.argsort(EigenValuesMix_LDA)[::-1]\n",
        "EigenValuesMix_LDA = EigenValuesMix_LDA[indices]\n",
        "EigenVectorsMix_LDA = EigenVectorsMix_LDA[:,indices]\n",
        "\n",
        "Sum=sum(EigenValuesMix_LDA)\n",
        "\n",
        "List = []\n",
        "\n",
        "prev1=0\n",
        "for k in range(len(EigenValuesMix_LDA)):\n",
        "  prev1+=EigenValuesMix_LDA[k]\n",
        "  Alpha_Mix=(prev1)/Sum\n",
        "  if(Alpha_Mix<=0.95):   \n",
        "    List.append(EigenVectorsMix_LDA[:,k])\n",
        "  else:\n",
        "    break  \n",
        "\n",
        "# print('Eignvectors length'+str(len(List)))\n",
        "#print('Eignvectors '+str(List))\n",
        "\n",
        "LDA_ProjectionMatrix_Mix= np.transpose(List)\n",
        "LDA_Projected_Training_Mix= np.dot(training_Matrix_Mix,LDA_ProjectionMatrix_Mix)\n",
        "LDA_Projected_Testing_Mix= np.dot(testing_Matrix_Mix,LDA_ProjectionMatrix_Mix)\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "classifier.fit(LDA_Projected_Training_Mix,trainingLabel_Mix)\n",
        "\n",
        "Testing_Label_LDA_Mix = classifier.predict(LDA_Projected_Testing_Mix) \n",
        "print('testingLabelMix'+str(Testing_Label_LDA_Mix))\n",
        "\n",
        "Acc_score_LDA_Mix = accuracy_score(testingLabel_Mix, Testing_Label_LDA_Mix)\n",
        "print('LDA Accuracy Faces vs Non Faces '+str(Acc_score_LDA_Mix))\n",
        "\n",
        "Failure=[]\n",
        "Success=[]\n",
        "for z in range(400):\n",
        "  if(z<200):\n",
        "    if(Testing_Label_LDA_Mix[z]==2):\n",
        "      Failure.append(LDA_Projected_Training_Mix[z])\n",
        "    else:\n",
        "      Success.append(LDA_Projected_Training_Mix[z])\n",
        "  else:\n",
        "    if(Testing_Label_LDA_Mix[z]==1):\n",
        "      Failure.append(LDA_Projected_Training_Mix[z])\n",
        "    else:\n",
        "      Success.append(LDA_Projected_Training_Mix[z])\n",
        "\n",
        "print('Number of Failure Cases = '+str(len(Failure)))\n",
        "print('Number of Success Cases = '+str(len(Success)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9cIrY1T29LT"
      },
      "source": [
        "iii. Plot the accuracy vs the number of non-faces images while fixing\n",
        "the number of face images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-cbiKPj29ow"
      },
      "source": [
        "\n",
        "new_Training = training\n",
        "new_Testing = testing\n",
        "AccuracyScoreList = []\n",
        "NonFace_number = [] \n",
        "\n",
        "for k in range(400):\n",
        "  if(k<10):\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_000'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "  elif(k<100):\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_00'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "  else:\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_0'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "\n",
        "  x2,y2= img2_resize.shape\n",
        "  vectorFlattened2= img2_resize.reshape(x2 * y2, 1).flatten()  \n",
        "  if(k%2==1):\n",
        "    new_Training.append(vectorFlattened2)\n",
        "    new_TrainingLabel.append(2)\n",
        "  else:\n",
        "    new_Testing.append(vectorFlattened2)\n",
        "    new_TestingLabel.append(2)   \n",
        "  \n",
        "  new_matrix.append(vectorFlattened2)\n",
        "\n",
        "  if(k==99 or k==199 or k==299 or k==399):\n",
        "    print('Training Label size = '+str(len(new_TrainingLabel)))\n",
        "    NonFace_number.append(k)\n",
        "    new_DataMatrix=np.asarray(new_matrix)\n",
        "    new_Mean=np.mean(new_DataMatrix,axis=0)\n",
        "    new_training_Matrix= np.asarray(new_Training)\n",
        "    new_testing_Matrix=np.asarray(new_Testing)\n",
        "    # print(new_TrainingLabel)\n",
        "    # print(img2_resize.shape)\n",
        "    # print(new_DataMatrix.shape)\n",
        "\n",
        "\n",
        "    new_MeanClass_Training= []\n",
        "\n",
        "    # Mean of first class (Faces)\n",
        "    new_FaceMatrix_Training=new_training_Matrix[0:200,:]\n",
        "    new_M1=np.mean(new_FaceMatrix_Training,axis=0)\n",
        "    new_MeanClass_Training.append(new_M1)\n",
        "\n",
        "    #Mean of second class (Non-Faces)\n",
        "    new_NonFaceMatrix_Training=new_training_Matrix[200:400,:]\n",
        "    new_M2=np.mean(new_NonFaceMatrix_Training,axis=0)\n",
        "    new_MeanClass_Training.append(new_M2)\n",
        "\n",
        "    new_MeanClass_TrainingArray=np.asarray(new_MeanClass_Training)\n",
        "    #print('meanclassmix'+str(new_MeanClass_TrainingArray.shape))\n",
        "\n",
        "    new_B_MatrixTraining= np.zeros((10304, 10304))\n",
        "\n",
        "    #print('Mean Class Training Array shape= '+str(new_MeanClass_TrainingArray.shape))\n",
        "\n",
        "    for s in range(2):\n",
        "      new_MeanK=new_MeanClass_TrainingArray[s]-new_Mean\n",
        "      new_MeanKT=new_MeanK.T\n",
        "      new_MeanProductK=2*(np.outer(new_MeanK,new_MeanKT))\n",
        "      new_B_MatrixTraining= new_B_MatrixTraining + new_MeanProductK\n",
        "\n",
        "    #print('B_Matrix Training ='+str(new_B_MatrixTraining.shape))\n",
        "\n",
        "    new_S_Matrix= np.zeros((10304,10304))\n",
        "\n",
        "    for m in range(2):\n",
        "      centeredLda=np.subtract(new_training_Matrix[m],new_MeanClass_TrainingArray[m])\n",
        "      centered_Transposed=centeredLda.T\n",
        "      centered_lda_product=np.outer(centered_Transposed,centeredLda)\n",
        "      new_S_Matrix=new_S_Matrix+centered_lda_product\n",
        "\n",
        "\n",
        "    #print('S_Matrix: '+ str(new_S_Matrix.shape))\n",
        "\n",
        "    new_A = np.linalg.inv(new_S_Matrix).dot(new_B_MatrixTraining)\n",
        "\n",
        "    new_EigenValues_LDA , new_EigenVectors_LDA = np.linalg.eigh(new_A)\n",
        "    indices = np.argsort(new_EigenValues_LDA)[::-1]\n",
        "    new_EigenValues_LDA = new_EigenValues_LDA[indices]\n",
        "    new_EigenVectors_LDA = new_EigenVectors_LDA[:,indices]\n",
        "\n",
        "    DominantVectors_Q7 = []\n",
        "    for r in range(39):\n",
        "      DominantVectors_Q7.append(new_EigenVectors_LDA[:,r])\n",
        "\n",
        "    print('Size of Dom = '+ str(len(DominantVectors_Q7)))\n",
        "\n",
        "    print('Eignvectors length Dom'+str(len(DominantVectors_Q7)))\n",
        "    new_LDA_ProjectionMatrix= np.transpose(DominantVectors_Q7)\n",
        "    new_LDA_Projected_Training= np.dot(new_training_Matrix,new_LDA_ProjectionMatrix)\n",
        "    new_LDA_Projected_Testing= np.dot(new_testing_Matrix,new_LDA_ProjectionMatrix)\n",
        "\n",
        "\n",
        "    classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "    classifier.fit(new_LDA_Projected_Training,new_TrainingLabel)\n",
        "\n",
        "    new_Testing_Label_LDA = classifier.predict(new_LDA_Projected_Testing) \n",
        "    #print('testingLabelMix'+str(new_Testing_Label_LDA))\n",
        "\n",
        "    new_Acc_score_LDA = accuracy_score(new_TestingLabel, new_Testing_Label_LDA)\n",
        "    print('Accuracymix'+str(new_Acc_score_LDA))\n",
        "    AccuracyScoreList.append(new_Acc_score_LDA)\n",
        "  \n",
        "    \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(NonFace_number, AccuracyScoreList)\n",
        "plt.xlabel('NonFace number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('NonFace number vs Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAjuNZAGbZc"
      },
      "source": [
        "8. Bonus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "3rqw-G4MGs2Z",
        "outputId": "595e00eb-46b7-4f11-fd4b-80b865481cad"
      },
      "source": [
        "DataMatrix_Label=[]\n",
        "x_train=[]\n",
        "x_test=[]\n",
        "y_train=[]\n",
        "y_test=[]\n",
        "for i in range(1,41):\n",
        "  for j in range(1,11):\n",
        "    img = cv2.imread(BASE + '/s'+ str(i)+ '/'+ str(j)+ '.pgm' , 0) # '0' for reading grayscale images \n",
        "    x,y= img.shape\n",
        "    vectorFlattened= img.reshape(x * y, 1).flatten()\n",
        "    if(j<=7):\n",
        "      x_train.append(vectorFlattened)\n",
        "      y_train.append(i)\n",
        "      trainingLabel_Mix.append(1)\n",
        "    else:\n",
        "      x_test.append(vectorFlattened)\n",
        "      y_test.append(i)\n",
        "    DataMatrix_Label.append(i)  \n",
        "\n",
        "#x_train, x_test,y_train,y_test = train_test_split(DataMatrix,DataMatrix_Label,test_size=0.30)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "training_Matrix_new= np.asarray(x_train)\n",
        "testing_Matrix_new=np.asarray(x_test)\n",
        "\n",
        "#Question 4 PCA\n",
        "\n",
        "covarience_new=np.cov(training_Matrix_new.T)\n",
        "EigenValues_PCA_new,EigenVectors_PCA_new= np.linalg.eigh(covarience_new)\n",
        "print('Covariance Mat new Shape:'+ str(covarience_new.shape))\n",
        "indices = np.argsort(EigenValues_PCA_new)[::-1]\n",
        "EigenValues_PCA_new = EigenValues_PCA_new[indices]\n",
        "EigenVectors_PCA_new = EigenVectors_PCA_new[:,indices]\n",
        "print('Eigen new'+str(EigenValues_PCA_new))\n",
        "Sum_new=sum(EigenValues_PCA_new)\n",
        "\n",
        "List1_new = []\n",
        "List2_new = []\n",
        "List3_new = []\n",
        "List4_new = []\n",
        "new=0\n",
        "for k in range(len(EigenValues_PCA_new)):\n",
        "  new+=EigenValues_PCA_new[k]\n",
        "  Alpha_new=(new)/Sum_new\n",
        "  if(Alpha_new<=0.8):   \n",
        "    List1_new.append(EigenVectors_PCA_new[:,k])\n",
        "  if(Alpha_new<=0.85):\n",
        "    List2_new.append(EigenVectors_PCA_new[:,k])\n",
        "  if(Alpha_new<=0.90):\n",
        "    List3_new.append(EigenVectors_PCA_new[:,k])\n",
        "  if(Alpha_new<=0.95):\n",
        "    List4_new.append(EigenVectors_PCA_new[:,k])  \n",
        "  else:\n",
        "    break  \n",
        "\n",
        "projection_matrix1_new=np.transpose(List1_new)\n",
        "projection_matrix2_new=np.transpose(List2_new)\n",
        "projection_matrix3_new=np.transpose(List3_new)\n",
        "projection_matrix4_new=np.transpose(List4_new)\n",
        "\n",
        "\n",
        "projectedtesting1_new=np.dot(testing_Matrix_new,projection_matrix1_new)\n",
        "projectedtraining1_new=np.dot(training_Matrix_new,projection_matrix1_new)\n",
        "\n",
        "projectedtesting2_new=np.dot(testing_Matrix_new,projection_matrix2_new)\n",
        "projectedtraining2_new=np.dot(training_Matrix_new,projection_matrix2_new)\n",
        "\n",
        "projectedtesting3_new=np.dot(testing_Matrix_new,projection_matrix3_new)\n",
        "projectedtraining3_new=np.dot(training_Matrix_new,projection_matrix3_new)\n",
        "\n",
        "projectedtesting4_new=np.dot(testing_Matrix_new,projection_matrix4_new)\n",
        "projectedtraining4_new=np.dot(training_Matrix_new,projection_matrix4_new)\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining1_new,y_train)\n",
        "\n",
        "Testing_Label1_new = classifier.predict(projectedtesting1_new)\n",
        "\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining2_new,y_train)\n",
        "\n",
        "Testing_Label2_new = classifier.predict(projectedtesting2_new)\n",
        "#print(Testing_Label2)\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining3_new,y_train)\n",
        "\n",
        "Testing_Label3_new = classifier.predict(projectedtesting3_new)\n",
        "#print(Testing_Label3)\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining4_new,y_train)\n",
        "\n",
        "Testing_Label4_new = classifier.predict(projectedtesting4_new)\n",
        "#print(Testing_Label4_new)\n",
        "\n",
        "\n",
        "Acc_score1_new =accuracy_score(y_test, Testing_Label1_new)\n",
        "print('Accuracy of Alpha=0.80: '+str(Acc_score1_new))\n",
        "Acc_score2_new = accuracy_score(y_test, Testing_Label2_new)\n",
        "print('Accuracy of Alpha=0.85: '+str(Acc_score2_new))\n",
        "Acc_score3_new = accuracy_score(y_test, Testing_Label3_new)\n",
        "print('Accuracy of Alpha=0.90: '+str(Acc_score3_new))\n",
        "Acc_score4_new = accuracy_score(y_test, Testing_Label4_new)\n",
        "print('Accuracy of Alpha=0.95: '+str(Acc_score4_new))\n",
        "\n",
        "# #Question 5 LDA\n",
        "\n",
        "MeanClass_Training_new= []\n",
        "\n",
        "for i in range(0,280,7):\n",
        "  newMatrix_Training_new=training_Matrix_new[i: i+7,:]\n",
        "  M_new=np.mean(newMatrix_Training_new,axis=0)\n",
        "  MeanClass_Training_new.append(M_new)\n",
        " \n",
        "MeanClass_TrainingArray_new=np.asarray(MeanClass_Training_new)\n",
        "\n",
        "B_MatrixTraining_new= np.zeros((10304, 10304))\n",
        "\n",
        "for j in range(40):\n",
        "  MeanK_new=MeanClass_TrainingArray_new[j]-mean\n",
        "  MeanKT_new=MeanK_new.T\n",
        "  MeanProductK_new=7*(np.outer(MeanK_new,MeanKT_new))\n",
        "  B_MatrixTraining_new= B_MatrixTraining_new + MeanProductK_new\n",
        "\n",
        "#print('B_Matrix Training New='+str(B_MatrixTraining_new))\n",
        "\n",
        "S_Matrix_new= np.zeros((10304,10304))\n",
        "\n",
        "for i in range(40):\n",
        "  newMatrix_Training_new=training_Matrix_new[i: i+7,:]\n",
        "  centeredLda_new=np.subtract(newMatrix_Training_new,MeanClass_TrainingArray_new[i])\n",
        "  centered_Transposed_new=centeredLda_new.T\n",
        "  centered_lda_product_new=np.dot(centered_Transposed_new,centeredLda_new)\n",
        "  S_Matrix_new=S_Matrix_new+centered_lda_product_new\n",
        "\n",
        "\n",
        "# #print('S_Matrix new: '+ str(S_Matrix_new))\n",
        "A_new = pinvh(S_Matrix_new).dot(B_MatrixTraining_new)\n",
        "\n",
        "EigenValues_LDA_new , EigenVctors_LDA_new = np.linalg.eigh(A_new)\n",
        "indices = np.argsort(EigenValues_LDA_new)[::-1]\n",
        "EigenValues_LDA_new = EigenValues_LDA_new[indices]\n",
        "EigenVctors_LDA_new = EigenVctors_LDA_new[:,indices]\n",
        "\n",
        "DominantVectors_new = []\n",
        "\n",
        "for i in range(39):\n",
        "\n",
        "  DominantVectors_new.append(EigenVctors_LDA_new[:,i])\n",
        "\n",
        "\n",
        "LDA_ProjectionMatrix_new= np.transpose(DominantVectors_new)\n",
        "LDA_Projected_Training_new= np.dot(training_Matrix_new,LDA_ProjectionMatrix_new)\n",
        "LDA_Projected_Testing_new= np.dot(testing_Matrix_new,LDA_ProjectionMatrix_new)\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "classifier.fit(LDA_Projected_Training_new,y_train)\n",
        "\n",
        "Testing_Label_LDA_new = classifier.predict(LDA_Projected_Testing_new) \n",
        "\n",
        "Acc_score_LDA_new = accuracy_score(y_test, Testing_Label_LDA_new)\n",
        "print('Accuracy using LDA'+str(Acc_score_LDA_new))\n",
        "\n",
        "Question 6 Classifier Tuning\n",
        "kList = [1, 3, 5, 7]\n",
        "#PCA\n",
        "#Alpha = 0.85 K = 1\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(projectedtraining4_new,y_train)\n",
        "\n",
        "Label1_PCA_new = classifier.predict(projectedtesting4_new)\n",
        "#print('PCA k=1 '+ str(Label1_PCA_new))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=3,weights='distance')\n",
        "classifier.fit(projectedtraining4_new,y_train)\n",
        "\n",
        "Label2_PCA_new= classifier.predict(projectedtesting4_new)\n",
        "#print('PCA k=3 '+ str(Label2_PCA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
        "classifier.fit(projectedtraining4_new,y_train)\n",
        "\n",
        "Label3_PCA_new = classifier.predict(projectedtesting4_new)\n",
        "#print('PCA k=5 '+ str(Label3_PCA))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
        "classifier.fit(projectedtraining4_new,y_train)\n",
        "\n",
        "Label4_PCA_new = classifier.predict(projectedtesting4_new)\n",
        "#print('PCA k=7 '+ str(Label4_PCA))\n",
        "\n",
        "\n",
        "Acc_score_PCA_k1_new = accuracy_score(y_test, Label1_PCA_new)\n",
        "print('PCA k=1 Acc Score:'+str(Acc_score_PCA_k1_new))\n",
        "\n",
        "Acc_score_PCA_k3_new = accuracy_score(y_test, Label2_PCA_new)\n",
        "print('PCA k=3 Acc Score:'+str(Acc_score_PCA_k3_new))\n",
        "\n",
        "Acc_score_PCA_k5_new = accuracy_score(y_test, Label3_PCA_new)\n",
        "print('PCA k=5 Acc Score:'+str(Acc_score_PCA_k5_new))\n",
        "\n",
        "Acc_score_PCA_k7_new = accuracy_score(y_test, Label4_PCA_new)\n",
        "print('PCA k=7 Acc Score:'+str(Acc_score_PCA_k7_new))\n",
        "\n",
        "PCA_Accuracies_new = [Acc_score_PCA_k1_new, Acc_score_PCA_k3_new, Acc_score_PCA_k5_new, Acc_score_PCA_k7_new]\n",
        " \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(kList, PCA_Accuracies_new)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('PCA Accuracy vs k value')\n",
        "plt.show()\n",
        "\n",
        "#LDA\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training_new,y_train)\n",
        "\n",
        "Label1_LDA_new = classifier.predict(LDA_Projected_Testing_new) \n",
        "#print('LDA k=1 '+ str(Label1_LDA_new))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=3,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training_new,y_train)\n",
        "\n",
        "Label2_LDA_new = classifier.predict(LDA_Projected_Testing_new) \n",
        "#print('LDA k=3 '+ str(Label2_LDA_new))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training_new,y_train)\n",
        "\n",
        "Label3_LDA_new = classifier.predict(LDA_Projected_Testing_new) \n",
        "#print('LDA k=5 '+ str(Label3_LDA_new))\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
        "classifier.fit(LDA_Projected_Training_new,y_train)\n",
        "\n",
        "Label4_LDA_new = classifier.predict(LDA_Projected_Testing_new) \n",
        "#print('LDA k=7 '+ str(Label4_LDA_new))\n",
        "\n",
        "Acc_score_LDA_k1_new = accuracy_score(y_test, Label1_LDA_new)\n",
        "print('LDA k=1 Acc Score:'+str(Acc_score_LDA_k1_new))\n",
        "\n",
        "Acc_score_LDA_k3_new = accuracy_score(y_test, Label2_LDA_new)\n",
        "print('LDA k=3 Acc Score:'+str(Acc_score_LDA_k3_new))\n",
        "\n",
        "Acc_score_LDA_k5_new = accuracy_score(y_test, Label3_LDA_new)\n",
        "print('LDA k=5 Acc Score:'+str(Acc_score_LDA_k5_new))\n",
        "\n",
        "Acc_score_LDA_k7_new = accuracy_score(y_test, Label4_LDA_new)\n",
        "print('LDA k=7 Acc Score:'+str(Acc_score_LDA_k7_new))\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "LDA_Accuracies_new = [Acc_score_LDA_k1_new, Acc_score_LDA_k3_new, Acc_score_LDA_k5_new, Acc_score_LDA_k7_new]\n",
        "plt.plot(kList, LDA_Accuracies_new)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('LDA Accuracy vs k value')\n",
        "plt.show()\n",
        "\n",
        "# # Question 7\n",
        "training_Mix = x_train\n",
        "testing_Mix = x_test\n",
        "\n",
        "#matrix_Mix=new_matrix#matrix#either 400 and 400 or 200 and 200 total matrix\n",
        "\n",
        "print('Lenghth of training Face: '+ str(len(training_Mix)))\n",
        "print('Lenghth of matrix Face: '+ str(len(matrix_Mix)))\n",
        "for k in range(400):\n",
        "\n",
        "  if(k<10):\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_000'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "  elif(k<100):\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_00'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "  else:\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_0'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "\n",
        "  x2,y2= img2_resize.shape\n",
        "  vectorFlattened2= img2_resize.reshape(x2 * y2, 1).flatten()  \n",
        "  if(k<=7):\n",
        "    training_Mix.append(vectorFlattened2)\n",
        "    trainingLabel_Mix.append(2)\n",
        "  else:\n",
        "    testing_Mix.append(vectorFlattened2)\n",
        "    testingLabel_Mix.append(2)  \n",
        "   \n",
        "  matrix_Mix.append(vectorFlattened2)\n",
        "\n",
        "\n",
        "\n",
        "print('len of Training = '+str(len(training_Mix)))\n",
        "DataMatrix_Mix=np.asarray(matrix_Mix)\n",
        "Mean_Mix=np.mean(DataMatrix_Mix,axis=0)\n",
        "training_Matrix_Mix= np.asarray(training_Mix)\n",
        "testing_Matrix_Mix=np.asarray(testing_Mix)\n",
        "print(trainingLabel_Mix)\n",
        "print(img2_resize.shape)\n",
        "print(DataMatrix_Mix.shape)\n",
        "    \n",
        "\n",
        "MeanClass_TrainingMix= []\n",
        "\n",
        "# Mean of first class (Faces)\n",
        "FaceMatrix_Training=training_Matrix_Mix[0:200,:]\n",
        "M1=np.mean(FaceMatrix_Training,axis=0)\n",
        "MeanClass_TrainingMix.append(M1)\n",
        "\n",
        "#Mean of second class (Non-Faces)\n",
        "NonFaceMatrix_Training=training_Matrix_Mix[200:400,:]\n",
        "M2=np.mean(NonFaceMatrix_Training,axis=0)\n",
        "MeanClass_TrainingMix.append(M2)\n",
        " \n",
        "MeanClass_TrainingArrayMix=np.asarray(MeanClass_TrainingMix)\n",
        "#print('meanclassmix'+str(MeanClass_TrainingArrayMix.shape))\n",
        "\n",
        "B_MatrixTraining_Mix= np.zeros((10304, 10304))\n",
        "\n",
        "#print('Mean Class Training Array shape= '+str(MeanClass_TrainingArrayMix.shape))\n",
        "\n",
        "for j in range(2):\n",
        "  MeanK=MeanClass_TrainingArrayMix[j]-Mean_Mix\n",
        "  MeanKT=MeanK.T\n",
        "  MeanProductK=2*(np.outer(MeanK,MeanKT))\n",
        "  B_MatrixTraining_Mix= B_MatrixTraining_Mix + MeanProductK\n",
        "\n",
        "#print('B_Matrix Training ='+str(B_MatrixTraining_Mix.shape))\n",
        "\n",
        "S_Matrix_Mix= np.zeros((10304,10304))\n",
        "\n",
        "for i in range(2):\n",
        "  centeredLda=np.subtract(training_Matrix_Mix[i],MeanClass_TrainingArrayMix[i])\n",
        "  centered_Transposed=centeredLda.T\n",
        "  centered_lda_product=np.outer(centered_Transposed,centeredLda)\n",
        "  S_Matrix_Mix=S_Matrix_Mix+centered_lda_product\n",
        "\n",
        "\n",
        "#print('S_Matrix: '+ str(S_Matrix_Mix.shape))\n",
        "\n",
        "A = np.linalg.inv(S_Matrix_Mix).dot(B_MatrixTraining_Mix)\n",
        "\n",
        "EigenValuesMix_LDA , EigenVectorsMix_LDA = np.linalg.eigh(A)\n",
        "indices = np.argsort(EigenValuesMix_LDA)[::-1]\n",
        "EigenValuesMix_LDA = EigenValuesMix_LDA[indices]\n",
        "EigenVectorsMix_LDA = EigenVectorsMix_LDA[:,indices]\n",
        "\n",
        "Sum=sum(EigenValuesMix_LDA)\n",
        "\n",
        "List = []\n",
        "\n",
        "prev1=0\n",
        "for k in range(len(EigenValuesMix_LDA)):\n",
        "  prev1+=EigenValuesMix_LDA[k]\n",
        "  Alpha_Mix=(prev1)/Sum\n",
        "  if(Alpha_Mix<=0.95):   \n",
        "    List.append(EigenVectorsMix_LDA[:,k])\n",
        "  else:\n",
        "    break  \n",
        "\n",
        "print('Eignvectors length'+str(len(List)))\n",
        "#print('Eignvectors '+str(List))\n",
        "\n",
        "LDA_ProjectionMatrix_Mix= np.transpose(List)\n",
        "LDA_Projected_Training_Mix= np.dot(training_Matrix_Mix,LDA_ProjectionMatrix_Mix)\n",
        "LDA_Projected_Testing_Mix= np.dot(testing_Matrix_Mix,LDA_ProjectionMatrix_Mix)\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "classifier.fit(LDA_Projected_Training_Mix,trainingLabel_Mix)\n",
        "\n",
        "Testing_Label_LDA_Mix = classifier.predict(LDA_Projected_Testing_Mix) \n",
        "print('testingLabelMix'+str(Testing_Label_LDA_Mix))\n",
        "\n",
        "Acc_score_LDA_Mix = accuracy_score(testingLabel_Mix, Testing_Label_LDA_Mix)\n",
        "print('Accuracymix'+str(Acc_score_LDA_Mix))\n",
        "Failure=[]\n",
        "Success=[]\n",
        "for z in range(400):\n",
        "  if(z<200):\n",
        "    if(Testing_Label_LDA_Mix[z]==2):\n",
        "      Failure.append(LDA_Projected_Training_Mix[z])\n",
        "    else:\n",
        "      Success.append(LDA_Projected_Training_Mix[z])\n",
        "  else:\n",
        "    if(Testing_Label_LDA_Mix[z]==1):\n",
        "      Failure.append(LDA_Projected_Training_Mix[z])\n",
        "    else:\n",
        "      Success.append(LDA_Projected_Training_Mix[z])\n",
        "\n",
        "print('Number of Failure Cases = '+str(len(Failure)))\n",
        "print('Number of Success Cases = '+str(len(Success)))\n",
        "\n",
        "# Question 7 iii\n",
        "new_Training = x_train\n",
        "new_Testing = x_test\n",
        "AccuracyScoreList = []\n",
        "NonFace_number = [] \n",
        "\n",
        "for k in range(400):\n",
        "  if(k<10):\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_000'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "  elif(k<100):\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_00'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "  else:\n",
        "    img2 = cv2.imread(Base2 + '/AnyConv.com__flower_0'+ str(k)+ '.pgm' , 0)\n",
        "    img2_resize=cv2.resize(img2,(112,92),interpolation=cv2.INTER_AREA)\n",
        "\n",
        "  x2,y2= img2_resize.shape\n",
        "  vectorFlattened2= img2_resize.reshape(x2 * y2, 1).flatten()  \n",
        "  if(k<=7):\n",
        "    new_Training.append(vectorFlattened2)\n",
        "    new_TrainingLabel.append(2)\n",
        "  else:\n",
        "    new_Testing.append(vectorFlattened2)\n",
        "    new_TestingLabel.append(2)   \n",
        "  \n",
        "  new_matrix.append(vectorFlattened2)\n",
        "\n",
        "  if(k==99 or k==199 or k==299 or k==399):\n",
        "    print('Training Label size = '+str(len(new_TrainingLabel)))\n",
        "    NonFace_number.append(k)\n",
        "    new_DataMatrix=np.asarray(new_matrix)\n",
        "    new_Mean=np.mean(new_DataMatrix,axis=0)\n",
        "    new_training_Matrix= np.asarray(new_Training)\n",
        "    new_testing_Matrix=np.asarray(new_Testing)\n",
        "    #print(new_TrainingLabel)\n",
        "    print(img2_resize.shape)\n",
        "    print(new_DataMatrix.shape)\n",
        "\n",
        "\n",
        "    new_MeanClass_Training= []\n",
        "\n",
        "    # Mean of first class (Faces)\n",
        "    new_FaceMatrix_Training=new_training_Matrix[0:200,:]\n",
        "    new_M1=np.mean(new_FaceMatrix_Training,axis=0)\n",
        "    new_MeanClass_Training.append(new_M1)\n",
        "\n",
        "    #Mean of second class (Non-Faces)\n",
        "    new_NonFaceMatrix_Training=new_training_Matrix[200:400,:]\n",
        "    new_M2=np.mean(new_NonFaceMatrix_Training,axis=0)\n",
        "    new_MeanClass_Training.append(new_M2)\n",
        "\n",
        "    new_MeanClass_TrainingArray=np.asarray(new_MeanClass_Training)\n",
        "    #print('meanclassmix'+str(new_MeanClass_TrainingArray.shape))\n",
        "\n",
        "    new_B_MatrixTraining= np.zeros((10304, 10304))\n",
        "\n",
        "    #print('Mean Class Training Array shape= '+str(new_MeanClass_TrainingArray.shape))\n",
        "\n",
        "    for s in range(2):\n",
        "      new_MeanK=new_MeanClass_TrainingArray[s]-new_Mean\n",
        "      new_MeanKT=new_MeanK.T\n",
        "      new_MeanProductK=2*(np.outer(new_MeanK,new_MeanKT))\n",
        "      new_B_MatrixTraining= new_B_MatrixTraining + new_MeanProductK\n",
        "\n",
        "    #print('B_Matrix Training ='+str(new_B_MatrixTraining.shape))\n",
        "\n",
        "    new_S_Matrix= np.zeros((10304,10304))\n",
        "\n",
        "    for m in range(2):\n",
        "      centeredLda=np.subtract(new_training_Matrix[m],new_MeanClass_TrainingArray[m])\n",
        "      centered_Transposed=centeredLda.T\n",
        "      centered_lda_product=np.outer(centered_Transposed,centeredLda)\n",
        "      new_S_Matrix=new_S_Matrix+centered_lda_product\n",
        "\n",
        "\n",
        "    #print('S_Matrix: '+ str(new_S_Matrix.shape))\n",
        "\n",
        "    new_A = np.linalg.inv(new_S_Matrix).dot(new_B_MatrixTraining)\n",
        "\n",
        "    new_EigenValues_LDA , new_EigenVectors_LDA = np.linalg.eigh(new_A)\n",
        "    indices = np.argsort(new_EigenValues_LDA)[::-1]\n",
        "    new_EigenValues_LDA = new_EigenValues_LDA[indices]\n",
        "    new_EigenVectors_LDA = new_EigenVectors_LDA[:,indices]\n",
        "\n",
        "    DominantVectors_Q7 = []\n",
        "    for r in range(39):\n",
        "      DominantVectors_Q7.append(new_EigenVectors_LDA[:,r])\n",
        "\n",
        "    print('Size of Dom = '+ str(len(DominantVectors_Q7)))\n",
        "\n",
        "    print('Eignvectors length Dom'+str(len(DominantVectors_Q7)))\n",
        "    new_LDA_ProjectionMatrix= np.transpose(DominantVectors_Q7)\n",
        "    new_LDA_Projected_Training= np.dot(new_training_Matrix,new_LDA_ProjectionMatrix)\n",
        "    new_LDA_Projected_Testing= np.dot(new_testing_Matrix,new_LDA_ProjectionMatrix)\n",
        "\n",
        "\n",
        "    classifier = KNeighborsClassifier(n_neighbors=1)\n",
        "    classifier.fit(new_LDA_Projected_Training,new_TrainingLabel)\n",
        "\n",
        "    new_Testing_Label_LDA = classifier.predict(new_LDA_Projected_Testing) \n",
        "    #print('testingLabelMix'+str(new_Testing_Label_LDA))\n",
        "\n",
        "    new_Acc_score_LDA = accuracy_score(new_TestingLabel, new_Testing_Label_LDA)\n",
        "    print('Accuracymix'+str(new_Acc_score_LDA))\n",
        "    AccuracyScoreList.append(new_Acc_score_LDA)\n",
        "    \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(NonFace_number, AccuracyScoreList)\n",
        "plt.xlabel('NonFace number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('NonFace number vs Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40]\n",
            "[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30, 31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 34, 34, 35, 35, 35, 36, 36, 36, 37, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40]\n",
            "Lenghth of training Face: 280\n",
            "Lenghth of matrix Face: 400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2bf123559d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mimg2_resize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m92\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/AnyConv.com__flower_0'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'.pgm'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0mimg2_resize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m92\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzauqqQk0Hu4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mroaDBWAnxE"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}